{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Sales Data Processing Pipeline – PySpark Implementation\n",
    "- company: Metyis\n",
    "- maintainer: Hamed Mahdavi Far\n",
    "- email: hamedmahdavifar31@gmail.com\n",
    "- date: 2025-08-08\n",
    "---\n",
    "## Overview\n",
    "This notebook outlines a PySpark-based data processing pipeline designed to efficiently handle and transform large volumes of monthly retail sales data. The pipeline reads raw CSV files from a source folder, performs data cleansing, deduplication and partitioning, and writes the optimized output to a designated `cleansed` folder.\n",
    "\n",
    "\n",
    "## Key Capabilities\n",
    "- **Ingestion** of multiple raw but structured CSV files representing monthly sales data.\n",
    "- **inspection** of the data to identify issues such as null values and fully duplicated rows etc.\n",
    "- **null value handling** to ensure data integrity and quality.\n",
    "- **Deduplication** using PySpark’s Window functions to ensure data quality to support accurate analytics.\n",
    "- **Data partitioning** strategy to support efficient querying and downstream analytics\n",
    "  compression\n",
    "---"
   ],
   "id": "d250aecef1276147"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Important Notes\n",
    "### Environment Setup for Running PySpark on Windows.\n",
    "\n",
    "Apache Spark relies on certain Hadoop utilities for internal operations On Windows systems, Spark expects access to the native `winutils.exe` binary.\n",
    "\n",
    "#### What I Did:\n",
    "- I manually downloaded the required Hadoop `winutils.exe` and accompanying `hadoop.dll` files for Windows from [https://github.com/steveloughran/winutils](https://github.com/steveloughran/winutils).\n",
    "- I placed the files in the directory: `C:\\hadoop\\bin`\n",
    "- I added the next cell of code inside the next cell in order to Tell Spark (and the underlying Hadoop libraries) where to find Hadoop binaries. "
   ],
   "id": "f214e7ef80596a91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1 Libraries",
   "id": "53d4500aa89298d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:06.101405Z",
     "start_time": "2025-08-07T00:28:06.086284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"HADOOP_HOME\"] = \"C:\\\\hadoop\"\n",
    "os.environ[\"hadoop.home.dir\"] = \"C:\\\\hadoop\"\n",
    "os.environ[\"PATH\"] += os.pathsep + \"C:\\\\hadoop\\\\bin\""
   ],
   "id": "a2bfb67ac95c1b12",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:06.134783Z",
     "start_time": "2025-08-07T00:28:06.122204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.shell import spark\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "from pyspark.sql.functions import year, month\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "from scripts.util import ( get_rows_with_nulls, \n",
    "                           rename_columns_to_snake_case, \n",
    "                           get_fully_duplicated_rows, \n",
    "                           drop_fully_duplicated_rows,\n",
    "                           read_and_preview_parquet, \n",
    "                           count_fully_duplicated_groups,\n",
    "                           show_min_max_dates_per_partition,\n",
    "                            find_any_duplication\n",
    "                           )\n",
    "\n"
   ],
   "id": "fdec8a1d84468256",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:06.169731Z",
     "start_time": "2025-08-07T00:28:06.162499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scripts.notebook_logger import get_notebook_logger\n",
    "logger = get_notebook_logger(\"notebook_pipeline\")\n",
    "logger.info(\"Starting the data processing pipeline notebook.\")"
   ],
   "id": "63c3533ba2af3723",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:06,165 — INFO — Starting the data processing pipeline notebook.`"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2 Inspection",
   "id": "526ca9b89f747b67"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Ingesting Multiple CSV Files into a Single Spark DataFrame\n",
    "\n",
    "In the following cell, I use PySpark to ingest **all CSV files** located in the `../data/sales_data/` directory. By using a wildcard pattern (`*.csv`), Spark automatically loads and combines all matching files into a **single distributed DataFrame**.\n",
    "\n",
    "\n"
   ],
   "id": "724ade5c129a573c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:06.222725Z",
     "start_time": "2025-08-07T00:28:06.209217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "\n",
    "sales_schema = StructType([\n",
    "    StructField(\"Order ID\", IntegerType(), True),\n",
    "    StructField(\"Product\", StringType(), True),\n",
    "    StructField(\"Quantity Ordered\", IntegerType(), True),\n",
    "    StructField(\"Price Each\", DoubleType(), True),\n",
    "    StructField(\"Order Date\", StringType(), True),\n",
    "    StructField(\"Purchase Address\", StringType(), True),\n",
    "])"
   ],
   "id": "ee19de3c8489ede3",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:06.497151Z",
     "start_time": "2025-08-07T00:28:06.322439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sales_df = (spark.read.option(\"header\", True).schema(sales_schema).csv(\"../data/sales_data/*.csv\"))\n",
    "logger.info(f\"DataFrame loaded with {sales_df.count()} rows and {len(sales_df.columns)} columns.\")"
   ],
   "id": "445cfef9876524f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:06,493 — INFO — DataFrame loaded with 186850 rows and 6 columns.`"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preview.",
   "id": "d1c71046602edebb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:06.623230Z",
     "start_time": "2025-08-07T00:28:06.563147Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df.show(5, truncate=False)",
   "id": "6dbdee7a524aaea8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+----------+--------------+--------------------------------------+\n",
      "|Order ID|Product             |Quantity Ordered|Price Each|Order Date    |Purchase Address                      |\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------------------------+\n",
      "|295665  |Macbook Pro Laptop  |1               |1700.0    |12/30/19 00:01|136 Church St, New York City, NY 10001|\n",
      "|295666  |LG Washing Machine  |1               |600.0     |12/29/19 07:03|562 2nd St, New York City, NY 10001   |\n",
      "|295667  |USB-C Charging Cable|1               |11.95     |12/12/19 18:21|277 Main St, New York City, NY 10001  |\n",
      "|295668  |27in FHD Monitor    |1               |149.99    |12/22/19 15:13|410 6th St, San Francisco, CA 94016   |\n",
      "|295669  |USB-C Charging Cable|1               |11.95     |12/18/19 12:38|43 Hill St, Atlanta, GA 30301         |\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:08.331587Z",
     "start_time": "2025-08-07T00:28:06.797961Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df.describe().show()",
   "id": "6ed457ea53a854cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------+------------------+-----------------+--------------+--------------------+\n",
      "|summary|         Order ID|     Product|  Quantity Ordered|       Price Each|    Order Date|    Purchase Address|\n",
      "+-------+-----------------+------------+------------------+-----------------+--------------+--------------------+\n",
      "|  count|           185950|      186305|            185950|           185950|        186305|              186305|\n",
      "|   mean|230417.5693788653|        NULL|1.1243828986286637|184.3997347674861|          NULL|                NULL|\n",
      "| stddev| 51512.7371099961|        NULL|0.4427926240286694|332.7313298843445|          NULL|                NULL|\n",
      "|    min|           141234|20in Monitor|                 1|             2.99|01/01/19 03:07|1 11th St, Atlant...|\n",
      "|    max|           319670|      iPhone|                 9|           1700.0|    Order Date|    Purchase Address|\n",
      "+-------+-----------------+------------+------------------+-----------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3 NULL Values ",
   "id": "6441dac0b80e45a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### checking the number null values in the dataframe.This function returns all rows with at least one null value in any row.",
   "id": "5cacc43de08d7fdd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:08.807691Z",
     "start_time": "2025-08-07T00:28:08.443821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows_with_null = get_rows_with_nulls(sales_df)\n",
    "rows_with_null.show(10, truncate=False)"
   ],
   "id": "cf3c70c11c78c5c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:08,446 — INFO — Checking for rows with null values in any column.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:08,739 — INFO — Found 900 rows with at least one null value.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|Order ID|Product|Quantity Ordered|Price Each|Order Date|Purchase Address|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|NULL    |Product|NULL            |NULL      |Order Date|Purchase Address|\n",
      "|NULL    |NULL   |NULL            |NULL      |NULL      |NULL            |\n",
      "|NULL    |NULL   |NULL            |NULL      |NULL      |NULL            |\n",
      "|NULL    |NULL   |NULL            |NULL      |NULL      |NULL            |\n",
      "|NULL    |Product|NULL            |NULL      |Order Date|Purchase Address|\n",
      "|NULL    |Product|NULL            |NULL      |Order Date|Purchase Address|\n",
      "|NULL    |NULL   |NULL            |NULL      |NULL      |NULL            |\n",
      "|NULL    |NULL   |NULL            |NULL      |NULL      |NULL            |\n",
      "|NULL    |NULL   |NULL            |NULL      |NULL      |NULL            |\n",
      "|NULL    |NULL   |NULL            |NULL      |NULL      |NULL            |\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### in this scenario we can drop all rows with null values because there is no vaaluable information in those rows.",
   "id": "11c8df0deeff7e7d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:09.208961Z",
     "start_time": "2025-08-07T00:28:08.864006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sales_df = sales_df.na.drop(how='any')\n",
    "logger.info(f\"After dropping null values, DataFrame has {sales_df.count()} rows and {len(sales_df.columns)} columns.\")"
   ],
   "id": "79af734c38140aa8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:09,204 — INFO — After dropping null values, DataFrame has 185950 rows and 6 columns.`"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Let's Check again for rows with null values after dropping them.",
   "id": "41ac3a04803eb230"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:10.202614Z",
     "start_time": "2025-08-07T00:28:09.247691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows_with_null = get_rows_with_nulls(sales_df)\n",
    "rows_with_null.show(10, truncate=False)"
   ],
   "id": "eaa68911dc26f6ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:09,253 — INFO — Checking for rows with null values in any column.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:09,769 — INFO — Found 0 rows with at least one null value.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "|Order ID|Product|Quantity Ordered|Price Each|Order Date|Purchase Address|\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "+--------+-------+----------------+----------+----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4 Naming Columns",
   "id": "9a0b50835febb5ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Renaming Columns for Consistency and Readability",
   "id": "7e4fab4378fbc4c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:10.299418Z",
     "start_time": "2025-08-07T00:28:10.273015Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df = rename_columns_to_snake_case(sales_df)",
   "id": "552fbf03098e099b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:10,275 — INFO — Renaming columns to snake_case format.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:10,295 — INFO — Successfully renamed all columns to snake_case.`"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5 Deduplication",
   "id": "ed87c4e25d95e157"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## What is defined as a duplicate?\n",
    "\n",
    "#### To identify duplicates, I grouped the data by `order_id` and filtered for those appearing more than once. The resulting rows represent potential duplicate entries based on the assumption that `order_id` is unique."
   ],
   "id": "626e03cf2ca0ebdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:13.248134Z",
     "start_time": "2025-08-07T00:28:10.494724Z"
    }
   },
   "cell_type": "code",
   "source": "find_any_duplication(sales_df, \"order_id\").show(10, truncate=False)",
   "id": "d78a95460e5699bb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:10,497 — INFO — Finding duplicated values in column: order_id`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:12,270 — INFO — Found 14649 duplicated rows.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------+----------------+----------+--------------+-----------------------------------+\n",
      "|order_id|product                   |quantity_ordered|price_each|order_date    |purchase_address                   |\n",
      "+--------+--------------------------+----------------+----------+--------------+-----------------------------------+\n",
      "|295681  |Google Phone              |1               |600.0     |12/25/19 12:37|79 Elm St, Boston, MA 02215        |\n",
      "|295681  |USB-C Charging Cable      |1               |11.95     |12/25/19 12:37|79 Elm St, Boston, MA 02215        |\n",
      "|295681  |Bose SoundSport Headphones|1               |99.99     |12/25/19 12:37|79 Elm St, Boston, MA 02215        |\n",
      "|295681  |Wired Headphones          |1               |11.99     |12/25/19 12:37|79 Elm St, Boston, MA 02215        |\n",
      "|295698  |Vareebadd Phone           |1               |400.0     |12/13/19 14:32|175 1st St, New York City, NY 10001|\n",
      "|295698  |USB-C Charging Cable      |2               |11.95     |12/13/19 14:32|175 1st St, New York City, NY 10001|\n",
      "|295703  |AA Batteries (4-pack)     |1               |3.84      |12/17/19 12:27|502 Jefferson St, Austin, TX 73301 |\n",
      "|295703  |Bose SoundSport Headphones|1               |99.99     |12/17/19 12:27|502 Jefferson St, Austin, TX 73301 |\n",
      "|295726  |iPhone                    |1               |700.0     |12/25/19 14:49|203 Lakeview St, Boston, MA 02215  |\n",
      "|295726  |Lightning Charging Cable  |1               |14.95     |12/25/19 14:49|203 Lakeview St, Boston, MA 02215  |\n",
      "+--------+--------------------------+----------------+----------+--------------+-----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 111
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Deduplication Strategy\n",
    "\n",
    "### Insight\n",
    "\n",
    "While `order_id` was initially assumed to be a unique identifier, further inspection showed that multiple entries with the same `order_id` can differ by product but share the same timestamp and address — indicating legitimate multi-item purchases. (same shopping cart)\n",
    "\n",
    "### Final Approach\n",
    "\n",
    "To preserve data integrity and not losing valuable information, deduplication is performed only on **fully identical rows** where all fields match exactly. This ensures that:\n",
    "\n",
    "- Multi-item orders are retained\n",
    "- Only true duplicates (identical records) are removed\n"
   ],
   "id": "fc5e693f551480f8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### checking the number of rows that are completely identical (fully duplicated) and inspecting the data.",
   "id": "d362ad0ba3bf87d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:17.228342Z",
     "start_time": "2025-08-07T00:28:13.324771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fully_duplicated_rows = get_fully_duplicated_rows(sales_df)\n",
    "fully_duplicated_rows.show(6, truncate=False)"
   ],
   "id": "cc44e82218e91aa7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:13,324 — INFO — Identifying fully duplicated rows (all fields match).`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:15,689 — INFO — Found 528 fully duplicated rows.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+----------------+----------+--------------+-------------------------------------+\n",
      "|order_id|product                 |quantity_ordered|price_each|order_date    |purchase_address                     |\n",
      "+--------+------------------------+----------------+----------+--------------+-------------------------------------+\n",
      "|304531  |Wired Headphones        |1               |11.99     |12/27/19 00:44|306 Jackson St, Los Angeles, CA 90001|\n",
      "|304531  |Wired Headphones        |1               |11.99     |12/27/19 00:44|306 Jackson St, Los Angeles, CA 90001|\n",
      "|266280  |USB-C Charging Cable    |1               |11.95     |10/02/19 11:11|53 Dogwood St, Portland, OR 97035    |\n",
      "|266280  |USB-C Charging Cable    |1               |11.95     |10/02/19 11:11|53 Dogwood St, Portland, OR 97035    |\n",
      "|274175  |Lightning Charging Cable|1               |14.95     |10/28/19 07:26|32 River St, Boston, MA 02215        |\n",
      "|274175  |Lightning Charging Cable|1               |14.95     |10/28/19 07:26|32 River St, Boston, MA 02215        |\n",
      "+--------+------------------------+----------------+----------+--------------+-------------------------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:19.115047Z",
     "start_time": "2025-08-07T00:28:17.341617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "duplication_stats = count_fully_duplicated_groups(sales_df)\n",
    "duplication_stats.show()"
   ],
   "id": "b347c9f847802709",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:17,349 — INFO — Counting fully duplicated record groups.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:17,391 — INFO — Counted fully duplicated groups successfully.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|count|groups|\n",
      "+-----+------+\n",
      "|    2|   264|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Remove fully duplicated rows from the DataFrame except one instance of each duplicate.",
   "id": "8a8e8b6be741fc81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:19.246762Z",
     "start_time": "2025-08-07T00:28:19.184218Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df = drop_fully_duplicated_rows(sales_df)",
   "id": "5340b6c70b8c7d3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:19,184 — INFO — Dropping fully duplicated rows.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:19,208 — INFO — Fully duplicated rows removed successfully.`"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:23.316372Z",
     "start_time": "2025-08-07T00:28:19.555012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fully_duplicated_rows = get_fully_duplicated_rows(sales_df)\n",
    "print(f\"Number of fully duplicated rows: {fully_duplicated_rows.count()}\")"
   ],
   "id": "31ffd5e9cd9da2f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:19,558 — INFO — Identifying fully duplicated rows (all fields match).`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:21,856 — INFO — Found 0 fully duplicated rows.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fully duplicated rows: 0\n"
     ]
    }
   ],
   "execution_count": 115
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6 Type Conversion",
   "id": "a64d11c52d26da35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Converting `order_date` to a Timestamp\n",
    "\n",
    "The `order_date` column is originally read as a string. We convert it into a proper `TimestampType` using `to_timestamp()` so that Spark can recognize and work with it as a datetime object. This enables accurate filtering, sorting, and usage of time-based functions.\n"
   ],
   "id": "8ab36b277226cdda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:23.357169Z",
     "start_time": "2025-08-07T00:28:23.340237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert 'order_date' to timestamp and overwrite it\n",
    "sales_df = sales_df.withColumn(\"order_date\", to_timestamp(\"order_date\", \"MM/dd/yy HH:mm\"))\n"
   ],
   "id": "287ed7460e8d0ee2",
   "outputs": [],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:23.455528Z",
     "start_time": "2025-08-07T00:28:23.388405Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df.printSchema()",
   "id": "65cd6b68af122000",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- quantity_ordered: integer (nullable = true)\n",
      " |-- price_each: double (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- purchase_address: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Previewing the DataFrame after converting `order_date` to a timestamp.",
   "id": "8af142a66aca0168"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:24.433657Z",
     "start_time": "2025-08-07T00:28:23.542354Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df.show(5, truncate=False)",
   "id": "e5175f4458466a9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+----------------+----------+-------------------+----------------------------------------+\n",
      "|order_id|product                 |quantity_ordered|price_each|order_date         |purchase_address                        |\n",
      "+--------+------------------------+----------------+----------+-------------------+----------------------------------------+\n",
      "|141238  |Wired Headphones        |1               |11.99     |2019-01-25 11:59:00|387 10th St, Austin, TX 73301           |\n",
      "|141240  |27in 4K Gaming Monitor  |1               |389.99    |2019-01-26 12:16:00|979 Park St, Los Angeles, CA 90001      |\n",
      "|141243  |Apple Airpods Headphones|1               |150.0     |2019-01-22 21:20:00|657 Johnson St, San Francisco, CA 94016 |\n",
      "|141264  |Apple Airpods Headphones|1               |150.0     |2019-01-03 09:46:00|937 Highland St, New York City, NY 10001|\n",
      "|141274  |USB-C Charging Cable    |1               |11.95     |2019-01-17 11:30:00|8 Jackson St, Los Angeles, CA 90001     |\n",
      "+--------+------------------------+----------------+----------+-------------------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7 Feature Engineering",
   "id": "e700398f0812a27d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Adding Year and Month Columns for Partitioning.",
   "id": "c4996229223382ff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:24.489401Z",
     "start_time": "2025-08-07T00:28:24.454465Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df = sales_df.withColumn(\"order_year\", year(\"order_date\")).withColumn(\"order_month\", month(\"order_date\"))",
   "id": "9d69e1e9b58abdfe",
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:24.656104Z",
     "start_time": "2025-08-07T00:28:24.645699Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df.printSchema()",
   "id": "e841e8bbb5284043",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- quantity_ordered: integer (nullable = true)\n",
      " |-- price_each: double (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- purchase_address: string (nullable = true)\n",
      " |-- order_year: integer (nullable = true)\n",
      " |-- order_month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:25.777349Z",
     "start_time": "2025-08-07T00:28:24.784070Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df.show(5, truncate=False)",
   "id": "e7a23d1af8f8cd4c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+----------------+----------+-------------------+----------------------------------------+----------+-----------+\n",
      "|order_id|product                 |quantity_ordered|price_each|order_date         |purchase_address                        |order_year|order_month|\n",
      "+--------+------------------------+----------------+----------+-------------------+----------------------------------------+----------+-----------+\n",
      "|141238  |Wired Headphones        |1               |11.99     |2019-01-25 11:59:00|387 10th St, Austin, TX 73301           |2019      |1          |\n",
      "|141240  |27in 4K Gaming Monitor  |1               |389.99    |2019-01-26 12:16:00|979 Park St, Los Angeles, CA 90001      |2019      |1          |\n",
      "|141243  |Apple Airpods Headphones|1               |150.0     |2019-01-22 21:20:00|657 Johnson St, San Francisco, CA 94016 |2019      |1          |\n",
      "|141264  |Apple Airpods Headphones|1               |150.0     |2019-01-03 09:46:00|937 Highland St, New York City, NY 10001|2019      |1          |\n",
      "|141274  |USB-C Charging Cable    |1               |11.95     |2019-01-17 11:30:00|8 Jackson St, Los Angeles, CA 90001     |2019      |1          |\n",
      "+--------+------------------------+----------------+----------+-------------------+----------------------------------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 121
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 8 Ingestion Time Tracking",
   "id": "7a7369c6889c21ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why Adding `ingestion_time` Column is neccessary\n",
    "\n",
    "- Tracks when each record was loaded, useful for data lineage and monitoring freshness.\n",
    "- Supports rollback or reprocessing by identifying data from specific ingestion windows.\n"
   ],
   "id": "59c2b6ca402d3bcc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:25.860092Z",
     "start_time": "2025-08-07T00:28:25.848661Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df = sales_df.withColumn(\"ingestion_date\", current_timestamp())",
   "id": "5c7f82a9230c7363",
   "outputs": [],
   "execution_count": 122
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Previewing the Dataframe after adding the `ingestion_ts` column.",
   "id": "a38188267648475d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:27.040815Z",
     "start_time": "2025-08-07T00:28:26.073172Z"
    }
   },
   "cell_type": "code",
   "source": "sales_df.show(5, truncate=False)",
   "id": "4ab1ff730c567bdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------------+----------------+----------+-------------------+----------------------------------------+----------+-----------+--------------------------+\n",
      "|order_id|product                 |quantity_ordered|price_each|order_date         |purchase_address                        |order_year|order_month|ingestion_date            |\n",
      "+--------+------------------------+----------------+----------+-------------------+----------------------------------------+----------+-----------+--------------------------+\n",
      "|141238  |Wired Headphones        |1               |11.99     |2019-01-25 11:59:00|387 10th St, Austin, TX 73301           |2019      |1          |2025-08-07 02:28:26.085683|\n",
      "|141240  |27in 4K Gaming Monitor  |1               |389.99    |2019-01-26 12:16:00|979 Park St, Los Angeles, CA 90001      |2019      |1          |2025-08-07 02:28:26.085683|\n",
      "|141243  |Apple Airpods Headphones|1               |150.0     |2019-01-22 21:20:00|657 Johnson St, San Francisco, CA 94016 |2019      |1          |2025-08-07 02:28:26.085683|\n",
      "|141264  |Apple Airpods Headphones|1               |150.0     |2019-01-03 09:46:00|937 Highland St, New York City, NY 10001|2019      |1          |2025-08-07 02:28:26.085683|\n",
      "|141274  |USB-C Charging Cable    |1               |11.95     |2019-01-17 11:30:00|8 Jackson St, Los Angeles, CA 90001     |2019      |1          |2025-08-07 02:28:26.085683|\n",
      "+--------+------------------------+----------------+----------+-------------------+----------------------------------------+----------+-----------+--------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " # 9 Output",
   "id": "37e8045576f3d708"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Saving Data in Parquet Format with Partitioning\n",
    "\n",
    "I save the cleansed dataset in **Parquet format** because it offers efficient, columnar storage with built-in compression and schema support. This format is ideal for analytics and large-scale processing.\n",
    "\n",
    "Additionally, I partition the data by `year` and `month` to enable faster querying and better organization in the data lake. Partitioning improves performance by allowing Spark to read only relevant subsets of the data.\n"
   ],
   "id": "156653e3604059a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:29.255596Z",
     "start_time": "2025-08-07T00:28:27.054182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_path = \"../data/cleansed\"\n",
    "sales_df.write.partitionBy(\"order_year\", \"order_month\").mode(\"overwrite\").parquet(output_path)"
   ],
   "id": "9185182d125d4756",
   "outputs": [],
   "execution_count": 124
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 10 Validation",
   "id": "d572bbbcc6b8d4e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Validating the Output",
   "id": "de3587c78caa6724"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:29.591185Z",
     "start_time": "2025-08-07T00:28:29.271593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_path = \"../data/cleansed\"\n",
    "verified_df = read_and_preview_parquet(output_path, spark)"
   ],
   "id": "c214b013dd1f4877",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:29,271 — INFO — Reading parquet files from: ../data/cleansed`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+----------+-------------------+--------------------+--------------------+----------+-----------+\n",
      "|order_id|             product|quantity_ordered|price_each|         order_date|    purchase_address|      ingestion_date|order_year|order_month|\n",
      "+--------+--------------------+----------------+----------+-------------------+--------------------+--------------------+----------+-----------+\n",
      "|  284978|    Wired Headphones|               1|     11.99|2019-12-01 00:09:00|361 Walnut St, Da...|2025-08-07 02:28:...|      2019|         12|\n",
      "|  288824|27in 4K Gaming Mo...|               1|    389.99|2019-12-01 00:16:00|865 Jackson St, A...|2025-08-07 02:28:...|      2019|         12|\n",
      "|  292269|    Wired Headphones|               1|     11.99|2019-12-01 01:30:00|629 13th St, New ...|2025-08-07 02:28:...|      2019|         12|\n",
      "|  294629|    Wired Headphones|               1|     11.99|2019-12-01 01:54:00|668 Ridge St, San...|2025-08-07 02:28:...|      2019|         12|\n",
      "|  295671|USB-C Charging Cable|               1|     11.95|2019-12-16 15:10:00|928 12th St, Port...|2025-08-07 02:28:...|      2019|         12|\n",
      "+--------+--------------------+----------------+----------+-------------------+--------------------+--------------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:29,587 — INFO — Preview of parquet data displayed successfully.`"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:29.651482Z",
     "start_time": "2025-08-07T00:28:29.644271Z"
    }
   },
   "cell_type": "code",
   "source": "verified_df.printSchema()",
   "id": "64260625a7ef6fa2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- order_id: integer (nullable = true)\n",
      " |-- product: string (nullable = true)\n",
      " |-- quantity_ordered: integer (nullable = true)\n",
      " |-- price_each: double (nullable = true)\n",
      " |-- order_date: timestamp (nullable = true)\n",
      " |-- purchase_address: string (nullable = true)\n",
      " |-- ingestion_date: timestamp (nullable = true)\n",
      " |-- order_year: integer (nullable = true)\n",
      " |-- order_month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:31.298635Z",
     "start_time": "2025-08-07T00:28:29.728617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "verified_df.describe().show()\n",
    "# nulls are due to the fact that those columns are string. they don't exist in the original data.\n",
    "# there is no date because sprak cant calculate dates"
   ],
   "id": "52a3819bd1f02fc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+------------------+------------------+--------------------+--------------------+-----------------+\n",
      "|summary|          order_id|     product|  quantity_ordered|        price_each|    purchase_address|          order_year|      order_month|\n",
      "+-------+------------------+------------+------------------+------------------+--------------------+--------------------+-----------------+\n",
      "|  count|            185686|      185686|            185686|            185686|              185686|              185686|           185686|\n",
      "|   mean|230411.37622653297|        NULL|1.1245435843305365|184.51925546358981|                NULL|  2019.0001831048114|7.058652779423327|\n",
      "| stddev| 51511.71718332067|        NULL|0.4430687383832869| 332.8438383900524|                NULL|0.013530420167169325|3.502932282404282|\n",
      "|    min|            141234|20in Monitor|                 1|              2.99|1 11th St, Atlant...|                2019|                1|\n",
      "|    max|            319670|      iPhone|                 9|            1700.0|999 Wilson St, Sa...|                2020|               12|\n",
      "+-------+------------------+------------+------------------+------------------+--------------------+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:31.814280Z",
     "start_time": "2025-08-07T00:28:31.329259Z"
    }
   },
   "cell_type": "code",
   "source": "show_min_max_dates_per_partition(verified_df)",
   "id": "8cb31da3fca58085",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:31,329 — INFO — Displaying min/max dates for each (order_year, order_month) partition.`"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------------------+-------------------+\n",
      "|order_year|order_month|min_date           |max_date           |\n",
      "+----------+-----------+-------------------+-------------------+\n",
      "|2019      |1          |2019-01-01 03:07:00|2019-01-31 23:35:00|\n",
      "|2019      |2          |2019-02-01 00:33:00|2019-02-28 23:59:00|\n",
      "|2019      |3          |2019-03-01 00:29:00|2019-03-31 23:46:00|\n",
      "|2019      |4          |2019-04-01 00:00:00|2019-04-30 23:49:00|\n",
      "|2019      |5          |2019-05-01 00:03:00|2019-05-31 23:49:00|\n",
      "|2019      |6          |2019-06-01 00:18:00|2019-06-30 23:56:00|\n",
      "|2019      |7          |2019-07-01 00:31:00|2019-07-31 23:43:00|\n",
      "|2019      |8          |2019-08-01 00:11:00|2019-08-31 23:57:00|\n",
      "|2019      |9          |2019-09-01 00:25:00|2019-09-30 23:59:00|\n",
      "|2019      |10         |2019-10-01 00:09:00|2019-10-31 23:51:00|\n",
      "|2019      |11         |2019-11-01 00:00:00|2019-11-30 23:56:00|\n",
      "|2019      |12         |2019-12-01 00:02:00|2019-12-31 23:53:00|\n",
      "|2020      |1          |2020-01-01 00:10:00|2020-01-01 05:13:00|\n",
      "+----------+-----------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "`2025-08-07 02:28:31,810 — INFO — Min and max dates per partition displayed successfully.`"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-07T00:28:31.860712Z",
     "start_time": "2025-08-07T00:28:31.857448Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "97db3168875cec34",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
